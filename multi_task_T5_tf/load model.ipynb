{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b53607a-4906-4475-a2ef-3d6bf5a68f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 14:27:20.505327: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-01 14:27:20.524671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740819440.547701   29550 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740819440.555114   29550 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 14:27:20.583897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e2281f-74b0-44be-9132-d9ff8f5c2d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740819516.756161   29550 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 48 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-03-01 14:28:36.781411: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1193] failed to allocate 48.75MiB (51118080 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-01 14:28:36.781570: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1193] failed to allocate 43.88MiB (46006272 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-01 14:28:36.781651: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1193] failed to allocate 39.49MiB (41405696 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-01 14:28:36.781726: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1193] failed to allocate 35.54MiB (37265152 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-01 14:28:47.016570: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 62.75MiB (rounded to 65798144)requested by op StatelessTruncatedNormalV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-03-01 14:28:47.016672: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1053] BFCAllocator dump for GPU_0_bfc\n",
      "2025-03-01 14:28:47.016692: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (256): \tTotal Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 40B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016708: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016722: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016734: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016745: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016756: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016772: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016783: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016794: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016806: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016828: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016839: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016861: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016872: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016884: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 0. 31.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016910: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016921: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016932: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016943: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-01 14:28:47.016956: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1076] Bin for 62.75MiB was 32.00MiB, Chunk State: \n",
      "2025-03-01 14:28:47.016967: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1089] Next region of size 33538816\n",
      "2025-03-01 14:28:47.016983: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000000 of size 256 next 1\n",
      "2025-03-01 14:28:47.016993: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000100 of size 1280 next 2\n",
      "2025-03-01 14:28:47.017003: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000600 of size 256 next 3\n",
      "2025-03-01 14:28:47.017012: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000700 of size 256 next 4\n",
      "2025-03-01 14:28:47.017021: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000800 of size 256 next 5\n",
      "2025-03-01 14:28:47.017048: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 76f2ba000900 of size 256 next 6\n",
      "2025-03-01 14:28:47.017059: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 76f2ba000a00 of size 33536256 next 18446744073709551615\n",
      "2025-03-01 14:28:47.017071: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114]      Summary of in-use Chunks by size: \n",
      "2025-03-01 14:28:47.017085: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 5 Chunks of size 256 totalling 1.2KiB\n",
      "2025-03-01 14:28:47.017095: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-03-01 14:28:47.017106: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1121] Sum Total of in-use chunks: 2.5KiB\n",
      "2025-03-01 14:28:47.017116: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1123] Total bytes in pool: 33538816 memory_limit_: 51118080 available bytes: 17579264 curr_region_allocation_bytes_: 102236160\n",
      "2025-03-01 14:28:47.017136: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Stats: \n",
      "Limit:                        51118080\n",
      "InUse:                            2560\n",
      "MaxInUse:                         2560\n",
      "NumAllocs:                           6\n",
      "MaxAllocSize:                     1280\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-01 14:28:47.017151: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________\n",
      "2025-03-01 14:28:47.017235: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at stateless_random_ops_v2.cc:64 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32128,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2025-03-01 14:28:47.017269: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32128,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32128,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:2977\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2975\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild_in_name_scope()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_in_name_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded:\n\u001b[1;32m   2980\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:1197\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build_in_name_scope\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_in_name_scope\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1197\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/transformers/models/t5/modeling_tf_t5.py:1579\u001b[0m, in \u001b[0;36mTFT5ForConditionalGeneration.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# The shared/tied weights expect to be in the model base namespace\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;66;03m# Adding \"/\" to the end (not the start!) of a tf.name_scope puts it in the root namespace rather than\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# the current one.\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mload_weight_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mname):\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/utils/tf_utils.py:371\u001b[0m, in \u001b[0;36mshape_type_conversion.<locals>.wrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m convert_shapes(input_shape, to_tuples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 371\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# Return shapes from `fn` as TensorShapes.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/layers/core/embedding.py:180\u001b[0m, in \u001b[0;36mEmbedding.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@tf_utils\u001b[39m\u001b[38;5;241m.\u001b[39mshape_type_conversion\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperimental_autocast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/engine/base_layer.py:705\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[1;32m    703\u001b[0m     getter \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(getter, layout\u001b[38;5;241m=\u001b[39mlayout)\n\u001b[0;32m--> 705\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m     name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[: variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:492\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    483\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    484\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 492\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_for_getter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/engine/base_layer_utils.py:137\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m    130\u001b[0m     use_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtensor\u001b[38;5;241m.\u001b[39mDVariable(\n\u001b[1;32m    154\u001b[0m         initial_value\u001b[38;5;241m=\u001b[39minit_val,\n\u001b[1;32m    155\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         shape\u001b[38;5;241m=\u001b[39mvariable_shape \u001b[38;5;28;01mif\u001b[39;00m variable_shape \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    165\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/initializers/initializers.py:525\u001b[0m, in \u001b[0;36mTruncatedNormal.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     _ensure_keras_seeded()\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mcall_with_layout(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mtruncated_normal,\n\u001b[1;32m    518\u001b[0m         layout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         nonce,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonce\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/tf_keras/src/backend.py:2144\u001b[0m, in \u001b[0;36mRandomGenerator.truncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2143\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_truncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m   2148\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2149\u001b[0m     mean\u001b[38;5;241m=\u001b[39mmean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2152\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2153\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32128,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: "
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e327194-1b09-4b73-a453-c138612a8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_right(input_ids, pad_token_id, decoder_start_token_id):\n",
    "    \"\"\"\n",
    "    Shifts input ids to the right by one position.\n",
    "    The first token becomes the decoder_start_token_id.\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(input_ids)[0]\n",
    "    start_tokens = tf.fill([batch_size, 1], decoder_start_token_id)\n",
    "    shifted_input_ids = tf.concat([start_tokens, input_ids[:, :-1]], axis=1)\n",
    "    return shifted_input_ids\n",
    "\n",
    "class MultiTaskT5(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_emotion_labels, num_sentiment_labels):\n",
    "        super(MultiTaskT5, self).__init__()\n",
    "        self.t5 = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.emotion_classifier = tf.keras.layers.Dense(\n",
    "            num_emotion_labels, activation='softmax', name=\"emotion_classifier\"\n",
    "        )\n",
    "        self.sentiment_classifier = tf.keras.layers.Dense(\n",
    "            num_sentiment_labels, activation='softmax', name=\"sentiment_classifier\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, task, training=False, labels=None):\n",
    "        if task in ['emotion', 'sentiment']:\n",
    "            encoder_outputs = self.t5.encoder(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                training=training\n",
    "            )\n",
    "            pooled_output = tf.reduce_mean(encoder_outputs.last_hidden_state, axis=1)\n",
    "            pooled_output = self.dropout(pooled_output, training=training)\n",
    "            if task == 'emotion':\n",
    "                return self.emotion_classifier(pooled_output)\n",
    "            else:\n",
    "                return self.sentiment_classifier(pooled_output)\n",
    "        elif task == 'summary':\n",
    "            if labels is None:\n",
    "                outputs = self.t5(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    training=training\n",
    "                )\n",
    "                return outputs.logits\n",
    "            else:\n",
    "                pad_token_id = self.t5.config.pad_token_id\n",
    "                decoder_start_token_id = self.t5.config.decoder_start_token_id\n",
    "                decoder_input_ids = shift_right(labels, pad_token_id, decoder_start_token_id)\n",
    "                outputs = self.t5(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    decoder_input_ids=decoder_input_ids,\n",
    "                    training=training\n",
    "                )\n",
    "                return outputs.logits\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported task type. Use 'emotion', 'sentiment', or 'summary'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729ca29-20cc-41e2-a89e-cc40819f82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "num_emotion_labels = 6\n",
    "num_sentiment_labels = 4  # Updated to 4 output labels for sentiment\n",
    "model = MultiTaskT5(model_name, num_emotion_labels, num_sentiment_labels)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56802e3b-739f-4a8f-9c3d-78da53b9e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights saved in H5 format.\n",
    "model.load_weights('./results/multi_task_T5_tf_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0accd7a-392a-41d6-beff-12d2f6bb9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from the saved directory.\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./results/multi_task_T5_tf/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbeea26-119c-4f8e-9659-8b227dca10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {3: 'positive', 2: 'neutral', 1: 'negative', 0: 'irrelevant'}\n",
    "\n",
    "emotion_mapping = {\n",
    "    0: \"anger\", \n",
    "    1: \"fear\", \n",
    "    2: \"joy\", \n",
    "    3: \"love\", \n",
    "    4: \"sadness\", \n",
    "    5: \"surprise\"\n",
    "}\n",
    "\n",
    "def decode_sentiment(label_code):\n",
    "    return sentiment_mapping.get(label_code, \"Unknown\")\n",
    "\n",
    "def decode_emotion(label_code):\n",
    "    return emotion_mapping.get(label_code, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8965e5d-1162-41bf-9ded-5b20622d8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, task):\n",
    "    if task in ['emotion', 'sentiment']:\n",
    "        # Tokenize the input with a moderate max_length.\n",
    "        inputs = tokenizer(text, return_tensors=\"tf\", max_length=128, truncation=True, padding=\"max_length\")\n",
    "        logits = model(inputs, task=task, training=False)\n",
    "        # Get the predicted label index.\n",
    "        pred_idx = int(tf.argmax(logits, axis=1).numpy()[0])\n",
    "        # Decode the prediction using our mapping functions.\n",
    "        if task == \"sentiment\":\n",
    "            return decode_sentiment(pred_idx)\n",
    "        elif task == \"emotion\":\n",
    "            return decode_emotion(pred_idx)\n",
    "    \n",
    "    elif task == 'summary':\n",
    "        # Prepend the summarization prefix as required by T5.\n",
    "        input_text = \"summarize: \" + text\n",
    "        # Tokenize with a longer max_length for summarization inputs.\n",
    "        inputs = tokenizer(input_text, return_tensors=\"tf\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        # Use the underlying T5 model's generate function.\n",
    "        generated_ids = model.t5.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=150,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        # Decode the generated token ids to text.\n",
    "        summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported task type. Use 'emotion', 'sentiment', or 'summary'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac20aae-b9c4-454b-96f9-4b2c4f4f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment classification\n",
    "sentiment_result = predict(\"smart guy, i would surely hire\", task=\"sentiment\")\n",
    "print(\"Sentiment Prediction:\", sentiment_result)\n",
    "\n",
    "# Test emotion classification\n",
    "emotion_result = predict(\"smart guy, i would surely hire\", task=\"emotion\")\n",
    "print(\"Emotion Prediction:\", emotion_result)\n",
    "\n",
    "# Test summarization\n",
    "summary_result = predict(\"This is an example text that we want to summarize.\", task=\"summary\")\n",
    "print(\"Summary Output:\", summary_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336763bb-60cb-490f-803e-fb9803ad4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart guy, i would surely hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487addc-95e9-451f-8fa7-7dd6c572ab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
