{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b53607a-4906-4475-a2ef-3d6bf5a68f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 14:41:51.587282: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-01 14:41:51.716453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740820311.780608    7233 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740820311.800140    7233 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 14:41:51.915997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e2281f-74b0-44be-9132-d9ff8f5c2d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "I0000 00:00:1740820320.634014    7233 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5315 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e327194-1b09-4b73-a453-c138612a8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_right(input_ids, pad_token_id, decoder_start_token_id):\n",
    "    \"\"\"\n",
    "    Shifts input ids to the right by one position.\n",
    "    The first token becomes the decoder_start_token_id.\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(input_ids)[0]\n",
    "    start_tokens = tf.fill([batch_size, 1], decoder_start_token_id)\n",
    "    shifted_input_ids = tf.concat([start_tokens, input_ids[:, :-1]], axis=1)\n",
    "    return shifted_input_ids\n",
    "\n",
    "class MultiTaskT5(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_emotion_labels, num_sentiment_labels):\n",
    "        super(MultiTaskT5, self).__init__()\n",
    "        self.t5 = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.emotion_classifier = tf.keras.layers.Dense(\n",
    "            num_emotion_labels, activation='softmax', name=\"emotion_classifier\"\n",
    "        )\n",
    "        self.sentiment_classifier = tf.keras.layers.Dense(\n",
    "            num_sentiment_labels, activation='softmax', name=\"sentiment_classifier\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, task, training=False, labels=None):\n",
    "        if task in ['emotion', 'sentiment']:\n",
    "            encoder_outputs = self.t5.encoder(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                training=training\n",
    "            )\n",
    "            pooled_output = tf.reduce_mean(encoder_outputs.last_hidden_state, axis=1)\n",
    "            pooled_output = self.dropout(pooled_output, training=training)\n",
    "            if task == 'emotion':\n",
    "                return self.emotion_classifier(pooled_output)\n",
    "            else:\n",
    "                return self.sentiment_classifier(pooled_output)\n",
    "        elif task == 'summary':\n",
    "            if labels is None:\n",
    "                outputs = self.t5(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    training=training\n",
    "                )\n",
    "                return outputs.logits\n",
    "            else:\n",
    "                pad_token_id = self.t5.config.pad_token_id\n",
    "                decoder_start_token_id = self.t5.config.decoder_start_token_id\n",
    "                decoder_input_ids = shift_right(labels, pad_token_id, decoder_start_token_id)\n",
    "                outputs = self.t5(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    decoder_input_ids=decoder_input_ids,\n",
    "                    training=training\n",
    "                )\n",
    "                return outputs.logits\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported task type. Use 'emotion', 'sentiment', or 'summary'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8729ca29-20cc-41e2-a89e-cc40819f82d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "num_emotion_labels = 6\n",
    "num_sentiment_labels = 4  # Updated to 4 output labels for sentiment\n",
    "model = MultiTaskT5(model_name, num_emotion_labels, num_sentiment_labels)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56802e3b-739f-4a8f-9c3d-78da53b9e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x75a77b950cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights saved in H5 format.\n",
    "model.load_weights('./results/multi_task_T5_tf_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0accd7a-392a-41d6-beff-12d2f6bb9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from the saved directory.\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./results/multi_task_T5_tf/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbeea26-119c-4f8e-9659-8b227dca10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {3: 'positive', 2: 'neutral', 1: 'negative', 0: 'irrelevant'}\n",
    "\n",
    "emotion_mapping = {\n",
    "    0: \"anger\", \n",
    "    1: \"fear\", \n",
    "    2: \"joy\", \n",
    "    3: \"love\", \n",
    "    4: \"sadness\", \n",
    "    5: \"surprise\"\n",
    "}\n",
    "\n",
    "def decode_sentiment(label_code):\n",
    "    return sentiment_mapping.get(label_code, \"Unknown\")\n",
    "\n",
    "def decode_emotion(label_code):\n",
    "    return emotion_mapping.get(label_code, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8965e5d-1162-41bf-9ded-5b20622d8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, task):\n",
    "    if task in ['emotion', 'sentiment']:\n",
    "        # Tokenize the input with a moderate max_length.\n",
    "        inputs = tokenizer(text, return_tensors=\"tf\", max_length=128, truncation=True, padding=\"max_length\")\n",
    "        logits = model(inputs, task=task, training=False)\n",
    "        # Get the predicted label index.\n",
    "        pred_idx = int(tf.argmax(logits, axis=1).numpy()[0])\n",
    "        # Decode the prediction using our mapping functions.\n",
    "        if task == \"sentiment\":\n",
    "            return decode_sentiment(pred_idx)\n",
    "        elif task == \"emotion\":\n",
    "            return decode_emotion(pred_idx)\n",
    "    \n",
    "    elif task == 'summary':\n",
    "        # Prepend the summarization prefix as required by T5.\n",
    "        input_text = \"summarize: \" + text\n",
    "        # Tokenize with a longer max_length for summarization inputs.\n",
    "        inputs = tokenizer(input_text, return_tensors=\"tf\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        # Use the underlying T5 model's generate function.\n",
    "        generated_ids = model.t5.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=150,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        # Decode the generated token ids to text.\n",
    "        summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported task type. Use 'emotion', 'sentiment', or 'summary'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac20aae-b9c4-454b-96f9-4b2c4f4f39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Prediction: negative\n",
      "Emotion Prediction: joy\n",
      "Summary Output: This is an example text that we want to summarize.\n"
     ]
    }
   ],
   "source": [
    "# Test sentiment classification\n",
    "sentiment_result = predict(\"i fell bad\", task=\"sentiment\")\n",
    "print(\"Sentiment Prediction:\", sentiment_result)\n",
    "\n",
    "# Test emotion classification\n",
    "emotion_result = predict(\"smart guy, i would surely hire\", task=\"emotion\")\n",
    "print(\"Emotion Prediction:\", emotion_result)\n",
    "\n",
    "# Test summarization\n",
    "summary_result = predict(\"This is an example text that we want to summarize.\", task=\"summary\")\n",
    "print(\"Summary Output:\", summary_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336763bb-60cb-490f-803e-fb9803ad4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Go to https://ground.news/bog to gain deeper i...\n",
       "1     I cannot believe that I wasted 40 minutes of m...\n",
       "2     You're actually really close to getting it to ...\n",
       "3     bro i literally went down this rabbit hole THI...\n",
       "4     I like the approach you have toward learning s...\n",
       "                            ...                        \n",
       "95    By the way, there is a problem you gonna encou...\n",
       "96    If you need to search something in a command o...\n",
       "97    I'm proud of this man's documentation of his t...\n",
       "98    You did it! When you see AMD GPU in your windo...\n",
       "99    More than 15 years ago I ran a server farm of ...\n",
       "Name: comments, Length: 100, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data = pd.read_json('./comments.json')\n",
    "pred_data['comments'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d487addc-95e9-451f-8fa7-7dd6c572ab0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "neutral\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "negative\n",
      "positive\n",
      "neutral\n",
      "negative\n",
      "positive\n",
      "neutral\n",
      "neutral\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "irrelevant\n",
      "positive\n",
      "irrelevant\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "neutral\n",
      "neutral\n",
      "irrelevant\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "irrelevant\n",
      "neutral\n",
      "neutral\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "neutral\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "irrelevant\n",
      "neutral\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "neutral\n",
      "irrelevant\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "neutral\n",
      "neutral\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "irrelevant\n",
      "neutral\n",
      "negative\n",
      "neutral\n",
      "irrelevant\n",
      "neutral\n",
      "negative\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for comment in list(pred_data['comments'][:100]):\n",
    "    print(predict(comment, task=\"sentiment\"))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9485ccbe-6e86-46a7-976b-72c77745b342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "anger\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "sadness\n",
      "sadness\n",
      "sadness\n",
      "joy\n",
      "sadness\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "for comment in list(pred_data['comments'][:100]):\n",
    "    print(predict(comment, task=\"emotion\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc92c93d-5007-4729-acef-32c84de12f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_comments=''\n",
    "for comment in list(pred_data['comments'][:10]):\n",
    "    summ_comments += comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8185e98e-e254-43e0-9906-428085909026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InspiringIm still waiting for the \"I don't really need this\" stagewatching this from an IT perspective really gives you an insight on how you might think something are just a given for you isn't the case for a normal person.\n"
     ]
    }
   ],
   "source": [
    "# for comment in list(pred_data['comments'][:10]):\n",
    "print(predict(summ_comments, task=\"summary\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01ccc6cb-5f82-4054-a690-d47f53d581e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go to https://ground.news/bog to gain deeper insights and keep up with current events. Sign up through my link for 50% off unlimited access to their Vantage Plan!I cannot believe that I wasted 40 minutes of my life watching a guy wasting a couple of days of his life following random tutorials on the internet. 10/10 liked it.You\\'re actually really close to getting it to work :) The way passing through a secondary GPU works is that it basically gives the VM software (in this case qemu) direct access to the graphics card - that\\'s why you couldn\\'t see anything in linux when you only had your dGPU plugged in to your monitor. \\n\\nAny output from the dGPU is going to display nothing until qemu starts up windows - so your monitor will automatically sync to where it gets video first, in this case, linux using your iGPU. By switching which graphics card output you are displaying on your monitor, you will be switching between seeing linux and windows.\\n\\nAlso, the reason you were still seeing windows in a little window on linux is because of the \"spice display\". This is essentially an emulated graphics card, similar to what virtualbox or vmware use - so when you saw two displays show up in windows (one being spice and the other being the dGPU), making the dGPU your primary display just moved the visible windows desktop to the dGPU output - which is visible by simply switching the monitor input. Personally, when I use gpu-passthrough I like to disable spice as I find it just ends up getting in the way.\\n\\nHope this helps you get your system up and running :)\\n\\nedit: unrelated note, are you using gpu-screen-recorder? it might help solve some of your recording issues in linuxbro i literally went down this rabbit hole THIS WEEK, perfect timingI like the approach you have toward learning something\\nJust do, fail and Google and watch guides and tutorials\\n\\nInspiringIm still waiting for the \"I don\\'t really need this\" stagewatching this from an IT perspective really gives you an insight on how you might think something are just a given for you isn\\'t the case for a normal person which a lot of people in IT tend to ignore.The second I realized this video wasn\\'t just a VM setup, but a journey to get GPU passthrough up and running, I knew I was about to witness absolute cinema.damn i was literally binge watching all the arch videos yesterday and you popped off today!It might not be as fun, but only following the arch wiki will probably make your life easier as it\\'s much more up-to-date and comprehensive than other tutorials.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summ_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386035f9-c800-49df-b916-c85d45fcc8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b21f64-fc58-4d73-aa43-547cddb16e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801a667-2527-4018-aa7f-282cbb30a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194061f1-b7db-4de8-8e17-335061570377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
